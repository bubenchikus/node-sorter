# node-sorter

### Дано:

Есть файл 1ТБ, состоящий из строк. Его нужно отсортировать при ограничении ОЗУ 500МБ.

---

### Конкретизации:

- Сортируются строки (не символы, не абзацы и тд).
- Используем двоичную систему для оценки размеров файлов и оперативки (1ТБ -> 1TiB = 1024^4 Bytes, 500МБ -> 500MiB = 500 \* 1024^2 Bytes). Для понимания масштаба: 1TiB/500MiB = ~2097.
- Тестить реальный 1ТБ файл нет возможности, поэтому будем работать с 1GiB (1024^3 Bytes) файлом и 500KiB (500 \* 1024 Bytes) ОЗУ.
- Допущение: в файле нет слишком длинных строк, которые невозможно разместить в доступной памяти.
- Для упрощения жизни используем везде кодировку utf-8.

---

### Общая логика решения задачи:

Работать целиком с тяжелым файлом не получится из-за ограничения на ОЗУ. Нужно использовать подход "разделяй и властвуй" - разбить его на более мелкие файлы, отсортировать их содержимое по отдельности и слепить обратно в большой отсортированный файл.

---

### Подзадачи:

- РАЗБИЕНИЕ ИЗНАЧАЛЬНОГО ФАЙЛА.
  - Новые файлы должны содержать строки целиком, при этом длины строк могут сильно варьироваться. Для эффективного использования памяти, размер файлов разбиения должен быть максимально близким к ее доступному объему (минус какая-то фиксированная память для выполнения операций), но не превышать его. Как это обеспечить?
  - Предлагаю следующий способ разбиения: заведем объект для хранения данных о том, какой объем текста можно еще разместить в каждом из уже созданных файлов. Далее читаем построчно изначальный файл. Если строку можно разместить в одном из существующих файлов, не привысив допустимый ОЗУ, размещаем, если нет - создаем новый файл и размещаем в нем. После этого обновляем данные по свободному пространству, и так пока не обойдем все строки изначального файла.
  - Вопрос в том, будет ли этот способ с дополнительными операциями более выигрышным, чем более тупой подход: если места в текущем файле достаточно для размещения строки, размещаем в нем, если нет - размещаем в новом файле. По предварительным прикидкам, ДА, но чтобы выяснить это наверняка, реализуем оба способа и произведем замеры потраченных ресурсов.
- ОБРАТНОЕ СЛИЯНИЕ.
  - Создаем новый файл и массив с номерами текущих строк (индексами) для каждого файла разбиения - сначала это нули.
  - Находим файл с "наименьшим" значением, лежащим по его текущему индексу. Присоединяем это значение к новому файлу, а к индексу этого файла разбиения прибавляем 1. Процесс повторяется, пока текущие индексы не пройдутся полностью по каждому файлу разбиения, и все строки не будут скопированы в новый файл в отсортированном порядке.

### NB:

- Мы реализуем сортировку для файла с произвольными строковыми данными. В реальности данные, полученные из одного источника, обладают похожей структурой, имеют закономерности и могут быть подвержены статистическому анализу, что позволяет делать дополнительные оптимизации.
